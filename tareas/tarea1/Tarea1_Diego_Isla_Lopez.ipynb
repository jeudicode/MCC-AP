{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea1_Diego-Isla-Lopez.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7G7t8jtAIMyssXxQeI3hf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeudicode/MCC-AP/blob/master/tareas/tarea1/Tarea1_Diego_Isla_Lopez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPkuxSk7eFog"
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "import os\n",
        "from itertools import islice as take\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets.utils as vutils\n",
        "import torchvision.transforms as trans\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torchsummary import summary\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUi5G_F1bNE1"
      },
      "source": [
        "# Ejercicio 1: Red de unidades de umbral lineal\n",
        "\n",
        "**Programa y evalúa una red de neuronas con funciones de activación escalón unitario que aproxime la operación XNOR.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXkamGTYE4MP"
      },
      "source": [
        "Definimos nuestras funciones que usaremos para representar la función de evaluación y de representación de neuronas y las capas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6DngYZReEGW"
      },
      "source": [
        "def escalon(z):\n",
        "    if z > 0.0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOg5tqHD1k6x"
      },
      "source": [
        "\n",
        "def neurona(x, w, b):\n",
        "  z = np.dot(w.T, x) + b\n",
        "  a = escalon(z)\n",
        "\n",
        "  return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrOHrs78gnov"
      },
      "source": [
        "def multicapa(x, W1, b1, W2, b2):\n",
        "  escv = np.vectorize(escalon)\n",
        "  a = escv(np.dot(W1.T, x) + b1)\n",
        "  return escv(np.dot(W2.T, a) + b2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdGJ12bRFlb1"
      },
      "source": [
        "Definimos el vector objetivo para la compuerta XNOR de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7VG1xTJFt63"
      },
      "source": [
        "y_xnor = [1., 0., 0., 1.]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WFgnhL1GRBv"
      },
      "source": [
        "Definimos el vector con las entradas posibles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bB-4LzcGUr6"
      },
      "source": [
        "X = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEa1ohSxP5S6"
      },
      "source": [
        "Para la estructura de la red, utilizamos una muy similar a la requerida para la compuerta XOR. En este caso, en lugar de usar una neurona que aplique la operación NAND, utilizamos una que aplique la operación NOR, además de una neurona que aplique la operación OR en la última capa. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VllZ3d9iwrN"
      },
      "source": [
        "Para esto, primero debemos obtener los pesos necesarios para la operación NOR y definir la salida esperada. En este caso, observamos que los pesos necesarios son -1 para ambas entradas con un sesgo de 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmzBJs06maCE"
      },
      "source": [
        "W1_nor = np.array([-1, -1])\n",
        "b1_nor = np.array([1])\n",
        "y_nor = np.array([1.,0.,0.,0.])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHiaSYwM1X3U"
      },
      "source": [
        "for i in range(X.shape[0]):\n",
        "  y_hat = neurona(X[i], W1_nor, b1_nor)\n",
        "  print('{0}\\t{1}\\t{2}\\t{3}'.format(X[i, 0], X[i, 1], y_nor[i], y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CV8F4r43hnU"
      },
      "source": [
        "De este modo, sabemos que los pesos y sesgos para las compuertas necesarias son:\n",
        "\n",
        "AND: W = [10, 10], b = -15\n",
        "\n",
        "NOR: W = [-1, -1], b = 1\n",
        "\n",
        "OR:  W = [10, 10], b = -5\n",
        "\n",
        "\n",
        "Representamos esto en la estructura de la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErbwjgqOP72v"
      },
      "source": [
        "W1 = np.array([[10, -1], [10, -1]])\n",
        "b1 = np.array([-15, 1])\n",
        "\n",
        "W2 = np.array([[10],[10]])\n",
        "b2 = np.array([-5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w097eGOwQFL9"
      },
      "source": [
        "Se realiza la evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCWEDZLDQG9X"
      },
      "source": [
        "for i in range(X.shape[0]):\n",
        "  y_hat = multicapa(X[i], W1, b1, W2, b2)\n",
        "  print('{0}\\t{1}\\t{2}\\t{3}'.format(X[i, 0], X[i, 1], y_xnor[i], y_hat[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHBYpAlT7g2-"
      },
      "source": [
        "\n",
        "# Ejercicio 2: Retropropagación en red densa\n",
        "\n",
        "**Programa el algoritmo de retropropagación usando NumPy para una tarea de clasificación binaria presuponiendo un red densa con dos capas ocultas y la función de pérdida de entropía cruzada binaria. Describe las fórmulas y reglas de actualización de los pesos y sesgos de cada capa y entrena y evalúa la red en algún conjunto de datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3q23DzGAMDE"
      },
      "source": [
        "Definimos nuestras funciones, actualizando la función de feed-forward y la función de retropropagación para trabajar con dos capas ocultas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRWly5fe8HtC"
      },
      "source": [
        "def sigmoide(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqhu-1xRAYGr"
      },
      "source": [
        "La función de activación seguirá siendo la sigmoide, dada por:\n",
        "\n",
        "$\\sigma(z) = \\frac{1}{1+e^-z}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksx_Vi_e8JfH"
      },
      "source": [
        "def derivada_sigmoide(x):\n",
        "    return np.multiply(sigmoide(x), (1.0 - sigmoide(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyQ0YJVzAlle"
      },
      "source": [
        "Del mismo modo, sabemos que la derivada de esta función es:\n",
        "\n",
        "$\\frac{\\partial \\sigma(z)}{\\partial z} = \\sigma(z)(1-\\sigma(z))$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpkXUwCSBNOu"
      },
      "source": [
        "La función de errror, ECB, se mantiene igual. Del mismo modo, el cálculo de la exactitud se mantiene sin cambios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH0sRcJ97_1v"
      },
      "source": [
        "def entropia_cruzada_binaria(y, p):\n",
        "    p[p == 0] = np.nextafter(0., 1.)\n",
        "    p[p == 1] = np.nextafter(1., 0.)\n",
        "    return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTeu14_BV58"
      },
      "source": [
        "$$\n",
        "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjK3w7Rv8LsA"
      },
      "source": [
        "def exactitud(y, y_predicha):\n",
        "    return (y == y_predicha).mean() * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Mz7PyUBk6E"
      },
      "source": [
        "$\\texttt{exactitud} = \\frac{\\texttt{correctos}}{\\texttt{total}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBgEvqarB2JX"
      },
      "source": [
        "Al agregar una capa extra, la propagación de las capas queda de la siguiente manera:\n",
        "\n",
        "\\begin{align}\n",
        "a^{\\{1\\}} &= x^{\\{i\\}}\\\\\n",
        "z^{\\{2\\}} &= W^{\\{1\\}} \\cdot a^{\\{1\\}} + b^{\\{1\\}}\\\\\n",
        "a^{\\{2\\}} &= \\sigma(z^{\\{2\\}})\\\\\n",
        "z^{\\{3\\}} &= W^{\\{2\\}} \\cdot a^{\\{2\\}} + b^{\\{2\\}}\\\\\n",
        "a^{\\{3\\}} &= \\sigma(z^{\\{3\\}})\\\\\n",
        "z^{\\{4\\}} &= W^{\\{3\\}} \\cdot a^{\\{3\\}} + b^{\\{3\\}}\\\\\n",
        "a^{\\{4\\}} &= \\sigma(z^{\\{4\\}})\\\\\n",
        "\\hat y^{\\{i\\}} &= a^{\\{4\\}}\n",
        "\\end{align}\n",
        "\n",
        "De este modo, agregamos los parámentros necesarios en las funciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxnr_wSG8Nm9"
      },
      "source": [
        "# en esta funcion agregamos una capa oculta más\n",
        "\n",
        "def hacia_adelante(x, W1, b1, W2, b2, W3, b3):\n",
        "    z2 = np.dot(W1.T, x[:, np.newaxis]) + b1\n",
        "    a2 = sigmoide(z2)\n",
        "    z3 = np.dot(W2.T, a2) + b2\n",
        "    a3 = sigmoide(z3)\n",
        "    z4 = np.dot(W3.T, a3) + b3\n",
        "  \n",
        "    y_hat = sigmoide(z4)\n",
        "\n",
        "    return z2, a2, z3, a3, z4, y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDG3JVJfU94-"
      },
      "source": [
        "\n",
        "def retropropagacion(X, y, alpha = 0.01, n_epocas = 100, n_ocultas = 10):\n",
        "    n_ejemplos = X.shape[0]\n",
        "    n_entradas = X.shape[1]\n",
        "        \n",
        "    # Inicialización de las matrices de pesos W y V\n",
        "    W1 = np.sqrt(1.0 / n_entradas) * np.random.randn(n_entradas, n_ocultas)\n",
        "    b1 = np.zeros((n_ocultas, 1))\n",
        "    \n",
        "    W2 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, n_ocultas)\n",
        "    b2 = np.zeros((n_ocultas, 1))\n",
        "\n",
        "    W3 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, 1)\n",
        "    b3 = np.zeros((1, 1))\n",
        "    \n",
        "    perdidas = np.zeros((n_epocas))\n",
        "    exactitudes = np.zeros((n_epocas))\n",
        "    y_predicha = np.zeros((y.shape))\n",
        "    for i in range(n_epocas):\n",
        "        for j in range(n_ejemplos):\n",
        "            z2, a2, z3, a3, z4, y_hat = hacia_adelante(X[j], W1, b1, W2, b2, W3, b3)\n",
        "\n",
        "            # gradiente de capa de salida\n",
        "            dz4 = y_hat - y[j]\n",
        "            dW3 = np.outer(a3, dz4)\n",
        "            db3 = dz4\n",
        "            \n",
        "            # cálculo de gradientes para W2 y b2 por retropropagación\n",
        "            dz3 = np.dot(W3, dz4) * derivada_sigmoide(z3)\n",
        "            dW2 = np.outer(a2, dz3)\n",
        "            db2 = dz3\n",
        "\n",
        "            # cálculo de gradientes para W1 y b1 por retropropagación\n",
        "            dz2 = np.dot(W2, dz3) * derivada_sigmoide(z2)\n",
        "            dW1 = np.outer(X[j], dz2)\n",
        "            db1 = dz2\n",
        "            \n",
        "            ####################################\n",
        "            # IMPORTANTE \n",
        "            # la actualización de los parámetros\n",
        "            # debe hacerse de forma simultánea\n",
        "            W3 = W3 - alpha * dW3\n",
        "            b3 = b3 - alpha * db3\n",
        "            W2 = W2 - alpha * dW2\n",
        "            b2 = b2 - alpha * db2\n",
        "            W1 = W1 - alpha * dW1\n",
        "            b1 = b1 - alpha * db1\n",
        "\n",
        "            y_predicha[j] = y_hat\n",
        "            \n",
        "        # calcula la pérdida en la época\n",
        "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
        "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
        "        print('Epoch {0}: Pérdida = {1} Exactitud = {2}'.format(i, \n",
        "                                                              perdidas[i], \n",
        "                                                              exactitudes[i]))\n",
        "\n",
        "    return W2, W3, perdidas, exactitudes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFeLGKBOC_26"
      },
      "source": [
        "Retomaremos el ejemplo del ejercicio anterior, entrenando la red para replicar el comportamiento de la compuerta XNOR:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOeCT2tCU22R"
      },
      "source": [
        "Configuramos los parámetros y llamamos el algoritmo de retropropagación. Para este caso, usamos una tasa de aprendizaje de 0.5, 1000 épocas y 3 neuronas por capa oculta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61otBkfRIdvr"
      },
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0, 1, 1, 0]]).T\n",
        "\n",
        "np.random.seed(1)\n",
        "W2, W3, perdidas, exactitudes = retropropagacion(X, \n",
        "                                                 y, \n",
        "                                                 alpha = 0.5, \n",
        "                                                 n_epocas = 1000,\n",
        "                                                 n_ocultas = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFe9nxxMKWEP"
      },
      "source": [
        "plt.plot(np.arange(perdidas.size), perdidas, label='ECB')\n",
        "plt.plot(np.arange(exactitudes.size), exactitudes, label='Exactitud')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-3Gb02LM-GC"
      },
      "source": [
        "En la gráfica es posible apreciar que el algoritmo es capaz de encontrar la configuración correcta alrededor de la época 500, además de que desde el inicio el valor de pérdida es bajo y logra disminuir gradualmente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8qSCjtf-YSc"
      },
      "source": [
        "# 3. Regresión lineal con PyTorch\n",
        "\n",
        "**Entrena y evalúa un modelo de regresión lineal para el conjunto de datos de calificaciones que considere los dos atributos de entrada.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_t20es8XcHP"
      },
      "source": [
        "Se carga el conjunto de datos de calificaciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk0ZGiXdXgve"
      },
      "source": [
        "URL = 'https://raw.githubusercontent.com/gibranfp/CursoAprendizajeProfundo/master/data/califs/califs.csv'\n",
        "base_dir = '../data/califs/'\n",
        "filename = 'califs.csv'\n",
        "filepath = os.path.join(base_dir, 'califs.csv')\n",
        "\n",
        "download_url(URL, base_dir, filename)\n",
        "\n",
        "torch.manual_seed(10) # para reproducibilidad\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx3uQVuIlbuc"
      },
      "source": [
        "df = pd.read_csv(filepath, names=['calif anterior','horas de estudio','calificación'])\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR5YPMOZmHgf"
      },
      "source": [
        "Graficamos tomando en cuenta ambos atributos de entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEViU1COmNEH",
        "outputId": "55d8239e-8404-49b2-c3b7-19fb400111d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "x_trn = np.array(df.iloc[:,0], dtype=\"float32\")[..., np.newaxis]\n",
        "y_trn = np.array(df.iloc[:,1], dtype=\"float32\")[..., np.newaxis]\n",
        "z_trn = np.array(df.iloc[:,2], dtype=\"float32\")[..., np.newaxis]\n",
        "\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.scatter3D(x_trn, y_trn, z_trn);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfKAuNurvNXU"
      },
      "source": [
        "Creamos la clase del dataset tomando en cuenta los dos atributos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh1wgCYus9Y6"
      },
      "source": [
        "class CalifDS:\n",
        "    \n",
        "    def __init__(self, X, Y, Z):\n",
        "        self.x = X\n",
        "        self.y = Y\n",
        "        self.z = Z\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        X = np.array([self.x[i], self.y[i]]).flatten()\n",
        "        y = self.z[i]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcx5-UWevhDG"
      },
      "source": [
        "Probamos el funcionamiento del dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S5D0a-ivgok"
      },
      "source": [
        "batch_size = 16\n",
        "ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "trn_dl = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(ds.__getitem__(0))\n",
        "for x, y in take(trn_dl, 1):\n",
        "    print(f'x shape={x.shape} dtype={x.dtype}')\n",
        "    print(f'y shape={y.shape} dtype={y.dtype}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUkUDdzN3xWo"
      },
      "source": [
        "Utilizaremos las interfaces de alto y medio nivel, tomando en cuenta los dos atributos de entrada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kog-NFku31W0"
      },
      "source": [
        "model_high = nn.Sequential(\n",
        "    nn.Linear(2, 1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpE4RXJP3-_g"
      },
      "source": [
        "class RegLin(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegLin, self).__init__()\n",
        "        self.fc = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model_mid = RegLin()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9BNj0eS4VXP"
      },
      "source": [
        "Verificando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emdo7VvN4YGr"
      },
      "source": [
        "print(model_high)\n",
        "print(model_mid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeUJASEvey1E"
      },
      "source": [
        "Verificamos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgo51dKR4s9Z"
      },
      "source": [
        "# inferencia con datos sintéticos\n",
        "x = torch.zeros(1,2)\n",
        "y_high = model_high(x)\n",
        "y_mid = model_mid(x)\n",
        "print(x.dtype, x.shape)\n",
        "print(y_mid.dtype, y_mid.shape)\n",
        "print(y_high.dtype, y_high.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY5HQ9rdewo_"
      },
      "source": [
        "Hacemos pruebas con diferentes parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZtjxpgG7Ey3"
      },
      "source": [
        "batches = [5, 10, 15, 20, 25] # tamaños de batch\n",
        "l_rates = [1e-3, 0.01, 0.2, 0.5, 0.8, 1] # tasas de aprendizaje\n",
        "epochs = [2, 5, 10, 50, 100] # números de épocas\n",
        "\n",
        "high_hist = []\n",
        "mid_hist = []\n",
        "\n",
        "# para alto nivel\n",
        "\n",
        "for batch in batches:\n",
        "  ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "  trn_dl = DataLoader(ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "  for rate in l_rates:\n",
        "    for epoch in epochs:\n",
        "\n",
        "      model_high = nn.Sequential(\n",
        "          nn.Linear(2, 1)\n",
        "      )\n",
        "\n",
        "      opt = optim.SGD(model_high.parameters(), lr=rate)\n",
        "\n",
        "      # historial de pérdida\n",
        "      loss_hist_high = []\n",
        "\n",
        "      for _ in range(epoch):\n",
        "        # entrenamiento de una época\n",
        "        for x, y_true in trn_dl:\n",
        "            # hacemos inferencia para obtener los logits\n",
        "            y_lgts = model_high(x)\n",
        "            # calculamos de pérdida\n",
        "            loss = F.mse_loss(y_lgts, y_true)\n",
        "            # vaciamos los gradientes\n",
        "            opt.zero_grad()\n",
        "            # retropropagamos\n",
        "            loss.backward()\n",
        "            # actulizamos parámetros\n",
        "            opt.step()\n",
        "            \n",
        "            # guardamos historial de pérdida\n",
        "            loss_hist_high.append(loss.item() * 100)\n",
        "\n",
        "        high_hist.append(loss_hist_high)\n",
        "\n",
        "# para nivel medio\n",
        "for batch in batches:\n",
        "  ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "  trn_dl = DataLoader(ds, batch_size=batch, shuffle=True)\n",
        "\n",
        "  for rate in l_rates:\n",
        "    for epoch in epochs:\n",
        "      model_mid = RegLin()\n",
        "      opt = optim.SGD(model_mid.parameters(), lr=rate)\n",
        "\n",
        "      # historial de pérdida\n",
        "      loss_hist_mid = []\n",
        "      for _ in range(epoch):\n",
        "\n",
        "        # entrenamiento de una época\n",
        "        for x, y_true in trn_dl:\n",
        "            # hacemos inferencia para obtener los logits\n",
        "            y_lgts = model_mid(x)\n",
        "            # print(y_lgts)\n",
        "            # calculamos de pérdida\n",
        "            loss = F.mse_loss(y_lgts, y_true)\n",
        "            # vaciamos los gradientes\n",
        "            opt.zero_grad()\n",
        "            # retropropagamos\n",
        "            loss.backward()\n",
        "            # actulizamos parámetros\n",
        "            opt.step()\n",
        "            \n",
        "            # guardamos historial de pérdida\n",
        "            loss_hist_mid.append(loss.item() * 100)\n",
        "\n",
        "        mid_hist.append(loss_hist_mid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrV4Ck4DGR3D"
      },
      "source": [
        "Graficamos el desempeño con la interfaz de alto nivel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUUVC3S-LJm8"
      },
      "source": [
        "colors_grph = [\"blue\", \"red\", \"green\", \"orange\", \"magenta\"]\n",
        "cnt_lss = 0\n",
        "for batch_size_i in range(len(batches)):\n",
        "  fig, axs = plt.subplots(len(epochs), len(l_rates), figsize=(20,17))\n",
        "\n",
        "  for learning_rate_i in range(len(l_rates)):\n",
        "    for epoch_value_i in range(len(epochs)):\n",
        "      axs[epoch_value_i][learning_rate_i].plot(high_hist[cnt_lss], color=colors_grph[batch_size_i])\n",
        "      cnt_lss += 1\n",
        "      axs[epoch_value_i][learning_rate_i].set_xlabel('iteraciones')\n",
        "      axs[epoch_value_i][learning_rate_i].set_ylabel('ECM')\n",
        "      axs[epoch_value_i][learning_rate_i].set_title('Epochs: ' + str(epochs[epoch_value_i])+ ' - LR: ' + str(l_rates[learning_rate_i]))\n",
        "  fig.suptitle('Batch Size: ' + str(batches[batch_size_i]))\n",
        "  fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkWZBB6MGMtI"
      },
      "source": [
        "Graficamos el desempeño con la función de nivel medio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1zXJhIIaWHi"
      },
      "source": [
        "colors_grph = [\"blue\", \"red\", \"green\", \"orange\", \"magenta\"]\n",
        "cnt_lss = 0\n",
        "for batch_size_i in range(len(batches)):\n",
        "  fig, axs = plt.subplots(len(epochs), len(l_rates), figsize=(20,17))\n",
        "\n",
        "  for learning_rate_i in range(len(l_rates)):\n",
        "    for epoch_value_i in range(len(epochs)):\n",
        "      axs[epoch_value_i][learning_rate_i].plot(mid_hist[cnt_lss], color=colors_grph[batch_size_i])\n",
        "      cnt_lss += 1\n",
        "      axs[epoch_value_i][learning_rate_i].set_xlabel('iteraciones')\n",
        "      axs[epoch_value_i][learning_rate_i].set_ylabel('ECM')\n",
        "      axs[epoch_value_i][learning_rate_i].set_title('Epochs: ' + str(epochs[epoch_value_i])+ ' - LR: ' + str(l_rates[learning_rate_i]))\n",
        "  fig.suptitle('Batch Size: ' + str(batches[batch_size_i]))\n",
        "  fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN3l3Vfzdl4m"
      },
      "source": [
        "Probamos ambos modelos con parámetros fijos para hacer inferencia y ver diferencias. Primero, probamos con una configuración que sea buena para el modelo de alto nivel y mala para el modelo de nivel medio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLps-3y0dnss"
      },
      "source": [
        "\n",
        "b_size = 2\n",
        "l_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "# probamos el modelo de alto nivel\n",
        "\n",
        "ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "trn_dl = DataLoader(ds, batch_size=b_size, shuffle=True)\n",
        "\n",
        "# redefinimos\n",
        "\n",
        "model_high = nn.Sequential(\n",
        "  nn.Linear(2, 1)\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model_high.parameters(), lr=l_rate)\n",
        "\n",
        "# entrenamos\n",
        "\n",
        "for _ in range(epochs):\n",
        "\n",
        "    # entrenamiento de una época\n",
        "    for x, y_true in trn_dl:\n",
        "        # hacemos inferencia para obtener los logits\n",
        "        y_lgts = model_high(x)\n",
        "        # calculamos de pérdida\n",
        "        loss = F.mse_loss(y_lgts, y_true)\n",
        "        # vaciamos los gradientes\n",
        "        opt.zero_grad()\n",
        "        # retropropagamos\n",
        "        loss.backward()\n",
        "        # actulizamos parámetros\n",
        "        opt.step()\n",
        "\n",
        "x_test = torch.tensor([[3., 12.]])\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model_high(x_test).numpy()\n",
        "\n",
        "[w, b] = model_high.parameters()\n",
        "print([w,b])\n",
        "print(\"Prediccion: \", y_pred[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R27_bSVbhXcC"
      },
      "source": [
        "# probamos el modelo de nivel medio\n",
        "\n",
        "ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "trn_dl = DataLoader(ds, batch_size=b_size, shuffle=True)\n",
        "\n",
        "# redefinimos\n",
        "\n",
        "model_mid = RegLin()\n",
        "\n",
        "opt = optim.SGD(model_mid.parameters(), lr=l_rate)\n",
        "\n",
        "# entrenamos\n",
        "\n",
        "for _ in range(epochs):\n",
        "\n",
        "    # entrenamiento de una época\n",
        "    for x, y_true in trn_dl:\n",
        "        # hacemos inferencia para obtener los logits\n",
        "        y_lgts = model_mid(x)\n",
        "        # calculamos de pérdida\n",
        "        loss = F.mse_loss(y_lgts, y_true)\n",
        "        # vaciamos los gradientes\n",
        "        opt.zero_grad()\n",
        "        # retropropagamos\n",
        "        loss.backward()\n",
        "        # actulizamos parámetros\n",
        "        opt.step()\n",
        "\n",
        "x_test = torch.tensor([[3., 12.]])\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model_mid(x_test).numpy()\n",
        "\n",
        "[w, b] = model_mid.parameters()\n",
        "print([w,b])\n",
        "print(\"Prediccion: \", y_pred[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuNpvZP_kZ9l"
      },
      "source": [
        "Ahora probaremos con una configuración que sea buena para ambos modelos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjplmdT1kiil"
      },
      "source": [
        "b_size = 5\n",
        "l_rate = 0.001\n",
        "epochs = 2\n",
        "\n",
        "\n",
        "# probamos el modelo de alto nivel\n",
        "\n",
        "ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "trn_dl = DataLoader(ds, batch_size=b_size, shuffle=True)\n",
        "\n",
        "# redefinimos\n",
        "\n",
        "model_high = nn.Sequential(\n",
        "  nn.Linear(2, 1)\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model_high.parameters(), lr=l_rate)\n",
        "\n",
        "# entrenamos\n",
        "\n",
        "for _ in range(epochs):\n",
        "\n",
        "    # entrenamiento de una época\n",
        "    for x, y_true in trn_dl:\n",
        "        # hacemos inferencia para obtener los logits\n",
        "        y_lgts = model_high(x)\n",
        "        # calculamos de pérdida\n",
        "        loss = F.mse_loss(y_lgts, y_true)\n",
        "        # vaciamos los gradientes\n",
        "        opt.zero_grad()\n",
        "        # retropropagamos\n",
        "        loss.backward()\n",
        "        # actulizamos parámetros\n",
        "        opt.step()\n",
        "\n",
        "x_test = torch.tensor([[3., 12.]])\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model_high(x_test).numpy()\n",
        "\n",
        "[w, b] = model_high.parameters()\n",
        "print([w,b])\n",
        "print(\"Prediccion: \", y_pred[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGb4mPlEkybO"
      },
      "source": [
        "# probamos el modelo de nivel medio\n",
        "\n",
        "ds = CalifDS(x_trn, y_trn, z_trn)\n",
        "trn_dl = DataLoader(ds, batch_size=b_size, shuffle=True)\n",
        "\n",
        "# redefinimos\n",
        "\n",
        "model_mid = RegLin()\n",
        "\n",
        "opt = optim.SGD(model_mid.parameters(), lr=l_rate)\n",
        "\n",
        "# entrenamos\n",
        "\n",
        "for _ in range(epochs):\n",
        "\n",
        "    # entrenamiento de una época\n",
        "    for x, y_true in trn_dl:\n",
        "        # hacemos inferencia para obtener los logits\n",
        "        y_lgts = model_mid(x)\n",
        "        # calculamos de pérdida\n",
        "        loss = F.mse_loss(y_lgts, y_true)\n",
        "        # vaciamos los gradientes\n",
        "        opt.zero_grad()\n",
        "        # retropropagamos\n",
        "        loss.backward()\n",
        "        # actulizamos parámetros\n",
        "        opt.step()\n",
        "\n",
        "x_test = torch.tensor([[3., 12.]])\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model_mid(x_test).numpy()\n",
        "\n",
        "[w, b] = model_mid.parameters()\n",
        "print([w,b])\n",
        "print(\"Prediccion: \", y_pred[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwJb9ojgh6br"
      },
      "source": [
        "**Discusión**\n",
        "\n",
        "Se hicieron dos pruebas: una con parámetros para los que el desempeño fue diferente para ambos modelos y otra en la que el desempeño fue similar. En ambos casos observamos que las predicciones son consistentes: 8.20 y 8.71 para el modelo de alto nivel, 7.65 y 7.04 para el modelo de nivel medio respectivamente.\n",
        "\n",
        "\n",
        "En general para el caso del modelo de nivel medio es posible ver cómo un número mayor de épocas hace que el desempeño de la optimización sea mayor, al contrario que con el modelo de alto nivel, el cual presenta más ruido conforme va aumentando el número de épocas. Sin embargo, el nivel de ruido es significativamente menor en el modelo de alto nivel. En el caso particular del modelo de alto nivel es posible observar que las tasas de aprendizaje hacen que el ruido aumente conforme se acercan a 1. En resumen, el modelo de alto nivel parece ser más sensible a los cambios en la tasa de aprendizaje y el modelo de nivel medio a los cambios en épocas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOU0DrkeDbjx"
      },
      "source": [
        "# 4. Red completamente conectada con PyTorch\n",
        "\n",
        "Implementa una red completamente conectada para la tarea de clasificación de imágenes sobre el conjunto de Fashion-MNIST, tomando en cuenta las siguientes especificaciones:\n",
        "\n",
        "* Explora con diferentes números de neuronas, capas, funciones de activación e hiperparámetros\n",
        "\n",
        "* Discute tus resultados con las distintas configuraciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQa-yIUemslv"
      },
      "source": [
        "Descargamos el conjunto de datos y obtenemos los parámetros para normalizar más adelante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78TfeZTlmuNu"
      },
      "source": [
        "# directorio de datos\n",
        "DATA_DIR = './data'\n",
        "# objeto para normalizacion de las imagenes\n",
        "transform = trans.Compose([\n",
        "    trans.ToTensor()\n",
        "])\n",
        "\n",
        "train_transform_meanstd = trans.Compose([trans.ToTensor()])\n",
        "\n",
        "# obtenemos el conjunto de entrenamiento normalizándolo como tensor\n",
        "train_set_meanstd = FashionMNIST(\n",
        "    root=DATA_DIR, \n",
        "    train=True, \n",
        "    download=True, \n",
        "    transform=train_transform_meanstd\n",
        "  )\n",
        "\n",
        "# obtenemos la media y desviacion estandar\n",
        "MEAN = train_set_meanstd.train_data.float().mean()/255.0\n",
        "MEAN = (MEAN.item(),)\n",
        "STD = train_set_meanstd.train_data.float().std()/255.0\n",
        "STD = (STD.item(),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mJgjcl5pEzv"
      },
      "source": [
        "Probaremos la arquitectura de la red con los siguientes parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoD2kd23pJcv"
      },
      "source": [
        "# Tasa de aprendizaje\n",
        "l_lrates = [0.01, 0.5]\n",
        "# epocss\n",
        "l_epochs = [5, 20, 50]\n",
        "# numero de neuronas\n",
        "l_neurons_values = [5, 10]\n",
        "# capas ocultas\n",
        "l_hidden = [2, 5]\n",
        "\n",
        "#funciones\n",
        "l_acts = [\n",
        "  nn.Sigmoid(),\n",
        "  nn.ReLU(),\n",
        "  nn.Tanh(),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# tamaño del lote\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# reproducibilidad\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzQ8bmFyJAw"
      },
      "source": [
        "Definiremos nuestra red neuronal modificando el constructor para recigbi el número de capas y la función de activación como parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST88PmWvyPEs"
      },
      "source": [
        "# definición del modelo\n",
        "# Se recibe como parametro el número de capas ocultas,\n",
        "# La capa 1 siempre tendra 128, la segunda 256, y la tercera 512\n",
        "class MLP(nn.Module):\n",
        "    \n",
        "    # inicializador\n",
        "    def __init__(self, n_hidden, activation_function_id, nvalues):\n",
        "        \n",
        "        # inicilización del objeto padre, obligatorio\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Función de activación a utilizar\n",
        "        self.activation_function_id = activation_function_id\n",
        "\n",
        "        # Tamaño de la entrada\n",
        "        self.input_size = 1 * 28 * 28\n",
        "        \n",
        "        # Capas ocultas\n",
        "        self.n_hidden = n_hidden\n",
        "        self.hidden = []\n",
        "        # Primer capa oculta\n",
        "        self.hidden.append(nn.Linear(self.input_size, l_neurons_values[nvalues]))\n",
        "        for hidden_i in range(1, self.n_hidden):\n",
        "          self.hidden.append(nn.Linear(\n",
        "              self.hidden[-1].out_features,\n",
        "              l_neurons_values[nvalues]\n",
        "              ))\n",
        "\n",
        "        # Capa de Salida\n",
        "        self.output = nn.Linear(self.hidden[-1].out_features, 10)\n",
        "    \n",
        "    # metodo para inferencia\n",
        "    def forward(self, x):\n",
        "\n",
        "        # aplanamos los pixeles de la imagen\n",
        "        # [N, 1, 28, 28] => [N, 1x28x28]\n",
        "        x = x.view(-1, self.input_size)\n",
        "       \n",
        "        # inferencia\n",
        "        # capas ocultas\n",
        "        for hidden_i in range(self.n_hidden):\n",
        "          x = self.hidden[hidden_i](x)\n",
        "          x = l_acts[self.activation_function_id](x)\n",
        "          # print(activation_functions_values[self.activation_function_id])\n",
        "          # print(x)\n",
        "        # Capa de salida\n",
        "        x = self.output(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw3FM8zY19Hb"
      },
      "source": [
        "Definimos el dataset y el dataloader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ly9mJz2BAx"
      },
      "source": [
        "# transformaciones para la imagen\n",
        "trn_tsfm = trans.Compose([\n",
        "    # convertimos a torch.Tensor y escalamos a [0,1]\n",
        "    trans.ToTensor(),\n",
        "    # estandarizamos: restamos la media y dividimos sobre la varianza\n",
        "    trans.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "# creamos un Dataset\n",
        "trn_ds = FashionMNIST(\n",
        "    root=DATA_DIR,\n",
        "    train=True,\n",
        "    transform=trn_tsfm\n",
        ")\n",
        "\n",
        "# creamos un DataLoader\n",
        "trn_dl = DataLoader(\n",
        "    trn_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# transformaciones para la imagen\n",
        "tst_tsfm = trans.Compose([\n",
        "    trans.ToTensor(),\n",
        "    trans.Normalize(MEAN, STD),\n",
        "])\n",
        "\n",
        "# creamos un Dataset\n",
        "tst_ds = FashionMNIST(\n",
        "    root=DATA_DIR, \n",
        "    train=False,\n",
        "    transform=tst_tsfm\n",
        ")\n",
        "\n",
        "# creamos un DataLoader\n",
        "tst_dl = DataLoader(\n",
        "    tst_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Eoi9Tq7f6O"
      },
      "source": [
        "Haremos las pruebas con todas las diferentes funciones. Comenzamos con la función sigmoide:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re0s9_KL7jng"
      },
      "source": [
        "# Historiales de perdida\n",
        "loss_hists = []\n",
        "acc_hists = []\n",
        "\n",
        "\n",
        "for ep in range(len(l_epochs)):\n",
        "\n",
        "\n",
        "  for hid in range(len(l_hidden)):\n",
        "\n",
        "\n",
        "    for rate in range(len(l_lrates)):\n",
        "\n",
        "      for n_value in range(len(l_neurons_values)):\n",
        "      \n",
        "        # Definimos el modelo\n",
        "        curr_model = FMLP(l_hidden[hid], 0, n_value)\n",
        "\n",
        "        # optimizador\n",
        "        opt = optim.SGD(\n",
        "            curr_model.parameters(), lr=l_rates[rate])\n",
        "        \n",
        "        # historial de pérdida\n",
        "        curr_loss_hist = []\n",
        "\n",
        "        # ciclo de entrenamiento\n",
        "        for curr_epoch_i in range(l_epochs[ep]):\n",
        "      \n",
        "          # entrenamiento de una época\n",
        "          for x, y_true in trn_dl:\n",
        "\n",
        "              # vaciamos los gradientes\n",
        "              opt.zero_grad()\n",
        "              # hacemos inferencia para obtener los logits\n",
        "              y_lgts = curr_model(x)\n",
        "              # calculamos la pérdida\n",
        "              loss = F.cross_entropy(y_lgts, y_true)\n",
        "              # retropropagamos\n",
        "              loss.backward()\n",
        "              # actulizamos parámetros\n",
        "              opt.step()\n",
        "\n",
        "              # agregamos al historial de pérdidas\n",
        "              curr_loss_hist.append(loss.item())\n",
        "\n",
        "        loss_hists.append(curr_loss_hist)\n",
        "\n",
        "   \n",
        "        # modelo en modo de evaluación\n",
        "        curr_model.eval()\n",
        "\n",
        "        with torch.no_grad(): \n",
        "                \n",
        "            accs = []\n",
        "            # validación de la época\n",
        "            for x, y_true in take(tst_dl,10):\n",
        "                # hacemos inferencia para obtener los logits\n",
        "                y_lgts = curr_model(x)\n",
        "                # calculamos las probabilidades\n",
        "                y_prob = F.softmax(y_lgts, 1)\n",
        "                # obtenemos la clase predicha\n",
        "                y_pred = torch.argmax(y_prob, 1)\n",
        "                \n",
        "                # calculamos la exactitud\n",
        "                acc = (y_true == y_pred).type(torch.float32).mean()\n",
        "\n",
        "                accs.append(acc.item() * 100)\n",
        "\n",
        "            acc = np.mean(accs)\n",
        "            acc_hists.append(acc)\n",
        "\n",
        "\n",
        "        print(f\"SIG - EP: {l_epochs[ep]} HIDDEN: {l_hidden[hid]} LR: {l_rates[rate]}\")\n",
        "        plt.plot(curr_loss_hist, color='red')\n",
        "        plt.xlabel('época')\n",
        "        plt.ylabel('pérdida')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nAyl37WyNft"
      },
      "source": [
        "En el caso de la función sigmoide vemos cómo la evolución tiende a reducir la pérdida. Sin embargo para ciertas épocas parece retroceder en la exactitud del desempeño. Esto podría deberse a la característica del desvanecimiento de gradiente de esta función."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Elf7qdxxwBb"
      },
      "source": [
        "Continuamos con la función ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtzfoRkpsGjr"
      },
      "source": [
        "# Historiales de perdida\n",
        "loss_hists = []\n",
        "acc_hists = []\n",
        "\n",
        "\n",
        "for ep in range(len(l_epochs)):\n",
        "\n",
        "\n",
        "  for hid in range(len(l_hidden)):\n",
        "\n",
        "\n",
        "    for rate in range(len(l_lrates)):\n",
        "\n",
        "      for n_value in range(len(l_neurons_values)):\n",
        "      \n",
        "        # Definimos el modelo\n",
        "        curr_model = FMLP(l_hidden[hid], 1, n_value)\n",
        "\n",
        "        # optimizador\n",
        "        opt = optim.SGD(\n",
        "            curr_model.parameters(), lr=l_rates[rate])\n",
        "        \n",
        "        # historial de pérdida\n",
        "        curr_loss_hist = []\n",
        "\n",
        "        # ciclo de entrenamiento\n",
        "        for curr_epoch_i in range(l_epochs[ep]):\n",
        "      \n",
        "          # entrenamiento de una época\n",
        "          for x, y_true in trn_dl:\n",
        "\n",
        "              # vaciamos los gradientes\n",
        "              opt.zero_grad()\n",
        "              # hacemos inferencia para obtener los logits\n",
        "              y_lgts = curr_model(x)\n",
        "              # calculamos la pérdida\n",
        "              loss = F.cross_entropy(y_lgts, y_true)\n",
        "              # retropropagamos\n",
        "              loss.backward()\n",
        "              # actulizamos parámetros\n",
        "              opt.step()\n",
        "\n",
        "              # agregamos al historial de pérdidas\n",
        "              curr_loss_hist.append(loss.item())\n",
        "\n",
        "        # save the current list of losses \n",
        "        loss_hists.append(curr_loss_hist)\n",
        "\n",
        "     \n",
        "        # modelo en modo de evaluación\n",
        "        curr_model.eval()\n",
        "\n",
        "        # evitamos que se registren las operaciones \n",
        "        # en la gráfica de cómputo\n",
        "        with torch.no_grad(): \n",
        "                \n",
        "            accs = []\n",
        "            # validación de la época\n",
        "            for x, y_true in take(tst_dl,10):\n",
        "                # hacemos inferencia para obtener los logits\n",
        "                y_lgts = curr_model(x)\n",
        "                # calculamos las probabilidades\n",
        "                y_prob = F.softmax(y_lgts, 1)\n",
        "                # obtenemos la clase predicha\n",
        "                y_pred = torch.argmax(y_prob, 1)\n",
        "                \n",
        "                # calculamos la exactitud\n",
        "                acc = (y_true == y_pred).type(torch.float32).mean()\n",
        "\n",
        "                accs.append(acc.item() * 100)\n",
        "\n",
        "            acc = np.mean(accs)\n",
        "            acc_hists.append(acc)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"ReLU - EP: {l_epochs[ep]} HIDDEN: {l_hidden[hid} LR: {l_rates[rate]}\")\n",
        "        plt.plot(curr_loss_hist, color='red')\n",
        "        plt.xlabel('época')\n",
        "        plt.ylabel('pérdida')\n",
        "        plt.show()\n",
        "        print(acc_hists[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkJJ0gwTzdIX"
      },
      "source": [
        "En el caso de la función ReLU es posible ver cómo tasas de aprendizaje más cercanas a 0.1 hacen que la función tenga mejor desempeño, al contrario de usar una tasa de 0.001 en la que es posible ver un desempeño muy bajo. A su vez, el número de neuronas en las capas ocultas tiene un efecto positivo conforme aumenta. Sin embargo, se observa el mejor desempeño con 5 épocas y 5 neuronas por capa oculta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuOnpcH3sGAK"
      },
      "source": [
        "Finalizamos con la función tangente hiperbólica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAygQOX8x4yu"
      },
      "source": [
        "# Historiales de perdida\n",
        "loss_hists = []\n",
        "acc_hists = []\n",
        "\n",
        "\n",
        "for ep in range(len(l_epochs)):\n",
        "\n",
        "\n",
        "  for hid in range(len(l_hidden)):\n",
        "\n",
        "    for rate in range(len(l_lrates)):\n",
        "\n",
        "      for n_value in range(len(l_neurons_values)):\n",
        "      \n",
        "        # Definimos el modelo\n",
        "        curr_model = FMLP(l_hidden[hid], 2, n_value)\n",
        "\n",
        "        # optimizador\n",
        "        opt = optim.SGD(\n",
        "            curr_model.parameters(), lr=l_rates[rate])\n",
        "        \n",
        "        # historial de pérdida\n",
        "        curr_loss_hist = []\n",
        "\n",
        "        # ciclo de entrenamiento\n",
        "        for curr_epoch_i in range(l_epochs[ep]):\n",
        "      \n",
        "          # entrenamiento de una época\n",
        "          for x, y_true in trn_dl:\n",
        "\n",
        "              # vaciamos los gradientes\n",
        "              opt.zero_grad()\n",
        "              # hacemos inferencia para obtener los logits\n",
        "              y_lgts = curr_model(x)\n",
        "              # calculamos la pérdida\n",
        "              loss = F.cross_entropy(y_lgts, y_true)\n",
        "              # retropropagamos\n",
        "              loss.backward()\n",
        "              # actulizamos parámetros\n",
        "              opt.step()\n",
        "\n",
        "              # agregamos al historial de pérdidas\n",
        "              curr_loss_hist.append(loss.item())\n",
        "\n",
        "        # save the current list of losses \n",
        "        loss_hists.append(curr_loss_hist)\n",
        "\n",
        "       \n",
        "        # modelo en modo de evaluación\n",
        "        curr_model.eval()\n",
        "\n",
        "        # evitamos que se registren las operaciones \n",
        "        # en la gráfica de cómputo\n",
        "        with torch.no_grad(): \n",
        "                \n",
        "            accs = []\n",
        "            # validación de la época\n",
        "            for x, y_true in take(tst_dl,10):\n",
        "                # hacemos inferencia para obtener los logits\n",
        "                y_lgts = curr_model(x)\n",
        "                # calculamos las probabilidades\n",
        "                y_prob = F.softmax(y_lgts, 1)\n",
        "                # obtenemos la clase predicha\n",
        "                y_pred = torch.argmax(y_prob, 1)\n",
        "                \n",
        "                # calculamos la exactitud\n",
        "                acc = (y_true == y_pred).type(torch.float32).mean()\n",
        "\n",
        "                accs.append(acc.item() * 100)\n",
        "\n",
        "            acc = np.mean(accs)\n",
        "            acc_hists.append(acc)\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"TanH - EP: {l_epochs[ep]} HIDDEN: {l_hidden[hid]} LR: {l_rates[rate]}\")\n",
        "        plt.plot(curr_loss_hist, color='red')\n",
        "        plt.xlabel('época')\n",
        "        plt.ylabel('pérdida')\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou2XbGYM4E5o"
      },
      "source": [
        "En el caso de la función de tangente hiperbólica podemos apreciar que, a comparación de la función sigmoide, existe una tendencia clara a reducir el valor de la pérdida en las diferentes iteraciones. Si bien esta función también presenta desvanecimiento de gradiente, el rango en el que acota los valores la hace más flexible y es posible apreciarlo en el desempeño con este problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SU2zLIE8O0q"
      },
      "source": [
        "**Conclusiones**\n",
        "\n",
        "En general es posible apreciar que las tres funciones tienen diferentes combinacines de parámentros en las que se comportan mejor. Algo apreciable en los tres casos es que tienen a estabilizarse en valores de pérdida significativamente lejanos del 0. Se recomienda buscar configuraciones diferentes a las utilizadas en este ejercicio para hacer un análisis más extensivo. "
      ]
    }
  ]
}